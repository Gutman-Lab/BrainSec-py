{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ComputeMaskAccuracy.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"j-xFkCiKC4n6","colab_type":"code","outputId":"d9c46b4e-b40a-43f8-adfc-460b3cfd1ab7","executionInfo":{"status":"ok","timestamp":1582955752943,"user_tz":480,"elapsed":436,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TEST_DIR = '/content/drive/My Drive/brain training/'\n","TEST_DIR = '/content/drive/My Drive/Alzheimer\\'s Research/brain training/Results/GreyWhiteMasks/'\n","TRUTH_DIR = '/content/drive/My Drive/Alzheimer\\'s Research/Ground Truth Accuracy Calculation/ground_truth_images/'\n","SAVE_FILENAME = 'AccuracyResults.csv' # Under TEST_DIR\n","SAVE_FILENAME_LATEX = 'AccuracyResults.txt' # Under TEST_DIR"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EItMHj1kCozW","colab_type":"code","cellView":"both","colab":{}},"source":["#@title\n","import os\n","import glob\n","import numpy as np\n","from tqdm import tqdm\n","import re\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyvHRpALDdy_","colab_type":"code","cellView":"both","colab":{}},"source":["#@title\n","# Stores expected image dimensions\n","IMAGEDIMNORM = np.array(\n","        [[55296, 47616], \n","        [73728, 47616], \n","        [66048, 46080], \n","        [69120, 36864], \n","        [59904, 43008], \n","        [56832, 39936], \n","        [62976, 47616], \n","        [58368, 44544], \n","        [50688, 47616], \n","        [58368, 47616], \n","        [55296, 46080], \n","        [72192, 47616], \n","        [69120, 47616], \n","        [49152, 43008], \n","        [50688, 36864], \n","        [55296, 46080], \n","        [55296, 41472], \n","        [56832, 43008]], dtype='int')\n","downscale = 128\n","IMAGEDIMORIG = np.array(\n","        [[53784, 47177], \n","        [73704, 46200], \n","        [65736, 45178], \n","        [67728, 36459], \n","        [59760, 41787], \n","        [55776, 39849], \n","        [61752, 46410], \n","        [57768, 43740], \n","        [49800, 47520], \n","        [57768, 47481], \n","        [53784, 45142], \n","        [71712, 47426], \n","        [67728, 47200], \n","        [47808, 41668], \n","        [49800, 36131], \n","        [53784, 45548], \n","        [53784, 41073], \n","        [55776, 41634]], dtype='int')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmtYIvPdD2dW","colab_type":"code","outputId":"ef069e35-8da6-4350-81d8-2fdc5165477f","executionInfo":{"status":"ok","timestamp":1582955754269,"user_tz":480,"elapsed":248,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#@title\n","# Get image names\n","image_names = glob.glob(TRUTH_DIR + \"*Grey.png\")\n","image_names = [imagename.split('/')[-1] for imagename in image_names]\n","image_names = [imagename.split('-Grey')[0] for imagename in image_names]\n","image_names = sorted(image_names)\n","print(image_names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['NA3777-02_AB', 'NA4077-02_AB', 'NA4092-02_AB', 'NA4107-02_AB', 'NA4160-02_AB', 'NA4195-02_AB', 'NA4256-02_AB', 'NA4299-02_AB', 'NA4391-02_AB', 'NA4450-02_AB', 'NA4463-02_AB', 'NA4471-02_AB', 'NA4553-02_AB', 'NA4626-02_AB', 'NA4672-02_AB', 'NA4675-02_AB', 'NA4691-02_AB', 'NA4695-02_AB']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7-RZV3zPTerK","colab_type":"text"},"source":["#### Generate ground-truth background masks"]},{"cell_type":"code","metadata":{"id":"WDBk5Rf7Ti39","colab_type":"code","outputId":"2a499c9f-62a0-4853-81ce-c2cb6428552b","executionInfo":{"status":"ok","timestamp":1576897816079,"user_tz":-480,"elapsed":803451,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["#@title\n","def img_frombytes(data):\n","  size = data.shape[::-1]\n","  databytes = np.packbits(data, axis=1)\n","  return Image.frombytes(mode='1', size=size, data=databytes)\n","\n","t = tqdm(total=len(image_names))\n","for i, imagename in enumerate(image_names):\n","  # Filename for testing and ground truth images\n","  truth_grey_img_name = imagename + \"-Grey.png\"\n","  truth_white_img_name = imagename + \"-White.png\"\n","\n","  # Load images\n","  truth_grey_arr = np.array(Image.open(TRUTH_DIR + truth_grey_img_name))\n","  truth_white_arr = np.array(Image.open(TRUTH_DIR + truth_white_img_name))\n","  assert(truth_grey_arr.shape[0] == IMAGEDIMORIG[i, 1] and truth_grey_arr.shape[1] == IMAGEDIMORIG[i, 0])\n","  assert(truth_white_arr.shape[0] == IMAGEDIMORIG[i, 1] and truth_white_arr.shape[1] == IMAGEDIMORIG[i, 0])\n","  assert(truth_grey_arr.dtype == np.bool)\n","  assert(truth_white_arr.dtype == np.bool)\n","\n","  # Update tqdm descriptions\n","  t.set_description_str(\"Image {}, Grey ({}), White ({})\".format(\n","      imagename, str(truth_grey_arr.shape), str(truth_white_arr.shape)) )\n","  t.refresh()\n","  t.write(\"\", end=' ')\n","\n","  # Generate background mask\n","  truth_back_arr = np.logical_not(np.logical_or(truth_grey_arr, truth_white_arr))\n","\n","  # Save background mask\n","  truth_back_img = img_frombytes(truth_back_arr)\n","  truth_back_img.save(TRUTH_DIR + imagename + '-Background.png')\n","\n","  t.update()\n","t.close()\n","\n","print('Done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image NA3777-02_AB, Grey ((47177, 53784)), White ((47177, 53784)):   0%|          | 0/18 [00:24<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4077-02_AB, Grey ((46200, 73704)), White ((46200, 73704)):   6%|▌         | 1/18 [01:49<10:50, 38.25s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4092-02_AB, Grey ((45178, 65736)), White ((45178, 65736)):  11%|█         | 2/18 [03:18<14:11, 53.21s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4107-02_AB, Grey ((36459, 67728)), White ((36459, 67728)):  17%|█▋        | 3/18 [04:30<15:59, 63.97s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4160-02_AB, Grey ((41787, 59760)), White ((41787, 59760)):  22%|██▏       | 4/18 [04:55<15:07, 64.85s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4195-02_AB, Grey ((39849, 55776)), White ((39849, 55776)):  28%|██▊       | 5/18 [05:24<11:41, 53.96s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4256-02_AB, Grey ((46410, 61752)), White ((46410, 61752)):  33%|███▎      | 6/18 [05:53<09:02, 45.18s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4299-02_AB, Grey ((43740, 57768)), White ((43740, 57768)):  39%|███▉      | 7/18 [06:26<07:40, 41.89s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4391-02_AB, Grey ((47520, 49800)), White ((47520, 49800)):  44%|████▍     | 8/18 [06:55<06:21, 38.19s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4450-02_AB, Grey ((47481, 57768)), White ((47481, 57768)):  50%|█████     | 9/18 [07:21<05:14, 35.00s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4463-02_AB, Grey ((45142, 53784)), White ((45142, 53784)):  56%|█████▌    | 10/18 [07:49<04:24, 33.03s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4471-02_AB, Grey ((47426, 71712)), White ((47426, 71712)):  61%|██████    | 11/18 [09:01<03:38, 31.17s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4553-02_AB, Grey ((47200, 67728)), White ((47200, 67728)):  67%|██████▋   | 12/18 [11:04<04:40, 46.83s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4626-02_AB, Grey ((41668, 47808)), White ((41668, 47808)):  72%|███████▏  | 13/18 [11:34<05:37, 67.58s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4672-02_AB, Grey ((36131, 49800)), White ((36131, 49800)):  78%|███████▊  | 14/18 [11:55<03:37, 54.38s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4675-02_AB, Grey ((45548, 53784)), White ((45548, 53784)):  83%|████████▎ | 15/18 [12:20<02:11, 43.85s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4691-02_AB, Grey ((41073, 53784)), White ((41073, 53784)):  89%|████████▉ | 16/18 [12:46<01:18, 39.34s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4695-02_AB, Grey ((41634, 55776)), White ((41634, 55776)):  94%|█████████▍| 17/18 [13:10<00:34, 34.63s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["\rImage NA4695-02_AB, Grey ((41634, 55776)), White ((41634, 55776)): 100%|██████████| 18/18 [13:22<00:00, 31.80s/it]"],"name":"stderr"},{"output_type":"stream","text":["Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KPboBUgY4bbX","colab_type":"code","outputId":"5041e906-934b-49b3-e9eb-1a5d9888d2d6","executionInfo":{"status":"ok","timestamp":1576924323357,"user_tz":-480,"elapsed":640473,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#@title\n","# Convert background masks from 8-bit to 1-bit\n","def img_frombytes(data):\n","  size = data.shape[::-1]\n","  databytes = np.packbits(data, axis=1)\n","  return Image.frombytes(mode='1', size=size, data=databytes)\n","\n","#NEW_TRUTH_DIR = '/content/drive/My Drive/Alzheimer\\'s Research/Ground Truth Accuracy Calculation/background/'\n","\n","t = tqdm(total=len(image_names))\n","for i, imagename in enumerate(image_names):\n","  # Filename for testing and ground truth images\n","  truth_back_img_name = imagename + \"-Background.png\"\n","\n","  # Load images\n","  truth_back_arr = np.array(Image.open(TRUTH_DIR + truth_back_img_name))\n","  assert(truth_back_arr.shape[0] == IMAGEDIMORIG[i, 1] and truth_back_arr.shape[1] == IMAGEDIMORIG[i, 0])\n","  assert(truth_back_arr.dtype == np.uint8)\n","\n","  # Update tqdm descriptions\n","  t.set_description_str(\"Image {}, Background ({})\".format(\n","      imagename, str(truth_back_arr.shape)) )\n","  t.refresh()\n","  t.write(\"\", end=' ')\n","\n","  # Create new background array\n","  truth_back_arr_new = np.zeros_like(truth_back_arr, dtype=np.bool)\n","  truth_back_arr_new[truth_back_arr>=1] = True\n","\n","  # Save background mask\n","  truth_back_img = img_frombytes(truth_back_arr_new)\n","  truth_back_img.save(TRUTH_DIR + imagename + '-Background.png')\n","\n","  t.update()\n","t.close()\n","\n","print('Done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image NA3777-02_AB, Background ((47177, 53784)):   0%|          | 0/18 [00:17<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4077-02_AB, Background ((46200, 73704)):   6%|▌         | 1/18 [01:43<08:53, 31.41s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4092-02_AB, Background ((45178, 65736)):  11%|█         | 2/18 [02:32<13:01, 48.86s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4107-02_AB, Background ((36459, 67728)):  17%|█▋        | 3/18 [03:17<12:00, 48.06s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4160-02_AB, Background ((41787, 59760)):  22%|██▏       | 4/18 [03:44<10:51, 46.55s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4195-02_AB, Background ((39849, 55776)):  28%|██▊       | 5/18 [04:09<08:49, 40.72s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4256-02_AB, Background ((46410, 61752)):  33%|███▎      | 6/18 [04:38<07:06, 35.50s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4299-02_AB, Background ((43740, 57768)):  39%|███▉      | 7/18 [05:07<06:23, 34.89s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4391-02_AB, Background ((47520, 49800)):  44%|████▍     | 8/18 [05:34<05:25, 32.55s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4450-02_AB, Background ((47481, 57768)):  50%|█████     | 9/18 [06:01<04:34, 30.53s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4463-02_AB, Background ((45142, 53784)):  56%|█████▌    | 10/18 [06:29<04:00, 30.12s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4471-02_AB, Background ((47426, 71712)):  61%|██████    | 11/18 [07:20<03:23, 29.06s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4553-02_AB, Background ((47200, 67728)):  67%|██████▋   | 12/18 [08:27<03:39, 36.59s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4626-02_AB, Background ((41668, 47808)):  72%|███████▏  | 13/18 [08:55<03:48, 45.66s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4672-02_AB, Background ((36131, 49800)):  78%|███████▊  | 14/18 [09:15<02:33, 38.47s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4675-02_AB, Background ((45548, 53784)):  83%|████████▎ | 15/18 [09:37<01:37, 32.53s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4691-02_AB, Background ((41073, 53784)):  89%|████████▉ | 16/18 [10:02<01:01, 30.55s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4695-02_AB, Background ((41634, 55776)):  94%|█████████▍| 17/18 [10:27<00:28, 28.53s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["\rImage NA4695-02_AB, Background ((41634, 55776)): 100%|██████████| 18/18 [10:38<00:00, 27.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"iCdJUE_kNzNI","colab_type":"text"},"source":["#### Calculate pixel accuracy, sensitivity, specificity and precision based on TN, FP, FN, TP"]},{"cell_type":"code","metadata":{"id":"dcKk50giD63P","colab_type":"code","outputId":"e72bee9d-a748-4f7c-f684-767c3150a3e9","executionInfo":{"status":"ok","timestamp":1576838943302,"user_tz":-480,"elapsed":132640,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["#@title\n","# Stores results: grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP\n","results = np.zeros((len(image_names), 8), dtype='int')\n","\n","t = tqdm(total=len(image_names))\n","for i, imagename in enumerate(image_names):\n","  # Filename for testing and ground truth images\n","  test_grey_img_name = imagename + \"-Grey.png\"\n","  test_white_img_name = imagename + \"-White.png\"\n","  truth_grey_img_name = imagename + \"-Grey.png\"\n","  truth_white_img_name = imagename + \"-White.png\"\n","\n","  ##### Testing Grey Matter Mask #####\n","  # Load images\n","  test_img = np.array(Image.open(TEST_DIR + test_grey_img_name))\n","  truth_img = Image.open(TRUTH_DIR + truth_grey_img_name)\n","  (width, height) = (IMAGEDIMNORM[i, 0] // downscale, IMAGEDIMNORM[i, 1] // downscale)\n","  truth_img = truth_img.resize((width, height), Image.BILINEAR)\n","  truth_img = np.array(truth_img)\n","\n","  # Check dimensions\n","  if not (test_img.shape[0] == IMAGEDIMNORM[i, 1]//downscale and test_img.shape[1] == IMAGEDIMNORM[i, 0]//downscale):\n","    print('\\t' + imagename + ' grey dimension WRONG!!!')\n","\n","  # Update tqdm descriptions\n","  t.set_description_str(\"Image {}, Test ({}), Ground Truth ({})\".format(\n","      imagename, str(test_img.shape), str(truth_img.shape)) )\n","  t.refresh()\n","  t.write(\"\", end=' ')\n","\n","  # Clip test_img to 1\n","  test_img[test_img>=1] = 1\n","\n","  # Calculate true and false segmentations\n","  width = truth_img.shape[1]\n","  height = truth_img.shape[0]\n","  grey_TP = np.multiply(test_img, truth_img).sum()\n","  grey_FP = np.multiply(test_img, np.logical_not(truth_img)).sum()\n","  grey_FN = np.multiply(np.logical_not(test_img), truth_img).sum()\n","  grey_TN = np.multiply(np.logical_not(test_img), np.logical_not(truth_img)).sum()\n","  \n","  # Check results\n","  grey_total = width*height\n","  if not (grey_total == grey_TP+grey_FP+grey_FN+grey_TN):\n","    print('\\t' + imagename + ' grey matter results WRONG!!!')\n","\n","  ##### Testing White Matter Mask #####\n","  # Load images\n","  test_img = np.array(Image.open(TEST_DIR + test_white_img_name))\n","  truth_img = Image.open(TRUTH_DIR + truth_white_img_name)\n","  (width, height) = (IMAGEDIMNORM[i, 0] // downscale, IMAGEDIMNORM[i, 1] // downscale)\n","  truth_img = truth_img.resize((width, height), Image.BILINEAR)\n","  truth_img = np.array(truth_img)\n","\n","  # Check dimensions\n","  if not (test_img.shape[0] == IMAGEDIMNORM[i, 1]//downscale and test_img.shape[1] == IMAGEDIMNORM[i, 0]//downscale):\n","    print('\\t' + imagename + ' white dimension WRONG!!!')\n","\n","  # Clip test_img to 1\n","  test_img[test_img>=1] = 1\n","\n","  # Calculate true and false segmentations\n","  width = truth_img.shape[1]\n","  height = truth_img.shape[0]\n","  white_TP = np.multiply(test_img, truth_img).sum()\n","  white_FP = np.multiply(test_img, np.logical_not(truth_img)).sum()\n","  white_FN = np.multiply(np.logical_not(test_img), truth_img).sum()\n","  white_TN = np.multiply(np.logical_not(test_img), np.logical_not(truth_img)).sum()\n","\n","  # Check results\n","  white_total = width*height\n","  if not (white_total == white_TN+white_FP+white_FN+white_TP):\n","    print('\\t' + imagename + ' white matter results WRONG!!!')\n","\n","  # Save results: grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP\n","  results[i, :] = [grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP]\n","\n","  t.update()\n","t.close()\n","\n","# Generate results file\n","with open(TEST_DIR + SAVE_FILENAME, \"w\") as f:\n","  f.write('Image Name,Grey_TN (px),Grey_FP (px),Grey_FN (px),Grey_TP (px),' +\n","          'White_TN (px),White_FP (px),White_FN (px),White_TP (px),' + \n","          'G_Accuracy (%),G_Misclassification Rate (%),G_Sensitivity (%),' +\n","          'G_Specificity (%),G_Precision (%),G_Prevalence (%),' + \n","          'W_Accuracy (%),W_Misclassification Rate (%),W_Sensitivity (%),' +\n","          'W_Specificity (%),W_Precision (%),W_Prevalence (%)\\n') \n","  accu_result = np.zeros((len(image_names), 12))\n","  for i, imagename in enumerate(image_names):\n","    total = results[i, 0]+results[i, 1]+results[i, 2]+results[i, 3]\n","    accu_result[i, 0]  = (results[i, 0]+results[i, 3])/total*100\n","    accu_result[i, 1]  = (results[i, 1]+results[i, 2])/total*100\n","    accu_result[i, 2]  = (results[i, 3]/(results[i, 2]+results[i, 3]))*100\n","    accu_result[i, 3]  = (results[i, 0]/(results[i, 0]+results[i, 1]))*100\n","    accu_result[i, 4]  = (results[i, 3]/(results[i, 1]+results[i, 3]))*100\n","    accu_result[i, 5]  = (results[i, 2]+results[i, 3])/total*100\n","    total = results[i, 4]+results[i, 5]+results[i, 6]+results[i, 7]\n","    accu_result[i, 6]  = (results[i, 4]+results[i, 7])/total*100\n","    accu_result[i, 7]  = (results[i, 5]+results[i, 6])/total*100\n","    accu_result[i, 8]  = (results[i, 7]/(results[i, 6]+results[i, 7]))*100\n","    accu_result[i, 9]  = (results[i, 4]/(results[i, 4]+results[i, 5]))*100\n","    accu_result[i, 10] = (results[i, 7]/(results[i, 5]+results[i, 7]))*100\n","    accu_result[i, 11] = (results[i, 6]+results[i, 7])/total*100\n","    f.write('%s,%d,%d,%d,%d,%d,%d,%d,%d,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f\\n' % \n","        (imagename, results[i, 0], results[i, 1], results[i, 2], results[i, 3], \n","            results[i, 4], results[i, 5], results[i, 6], results[i, 7], \n","            accu_result[i, 0], accu_result[i, 1], accu_result[i, 2], \n","            accu_result[i, 3], accu_result[i, 4], accu_result[i, 5], \n","            accu_result[i, 6], accu_result[i, 7], accu_result[i, 8], \n","            accu_result[i, 9], accu_result[i, 10], accu_result[i, 11]))\n","  f.write('-' * 230 + '\\n')\n","  f.write('Average,%d,%d,%d,%d,%d,%d,%d,%d,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f\\n' % \n","          (np.mean(results[:, 0]), np.mean(results[:, 1]), np.mean(results[:, 2]), np.mean(results[:, 3]), \n","              np.mean(results[:, 4]), np.mean(results[:, 5]), np.mean(results[:, 6]), np.mean(results[:, 7]), \n","              np.mean(accu_result[:, 0]), np.mean(accu_result[:, 1]), np.mean(accu_result[:, 2]), \n","              np.mean(accu_result[:, 3]), np.mean(accu_result[:, 4]), np.mean(accu_result[:, 5]), \n","              np.mean(accu_result[:, 6]), np.mean(accu_result[:, 7]), np.mean(accu_result[:, 8]), \n","              np.mean(accu_result[:, 9]), np.mean(accu_result[:, 10]), np.mean(accu_result[:, 11])))\n","\n","# Generate results file for LaTeX\n","with open(TEST_DIR + SAVE_FILENAME_LATEX, \"w\") as f:\n","  # Grey Matter\n","  f.write('Image Name,Grey_TN (px),Grey_FP (px),Grey_FN (px),Grey_TP (px),' +\n","          'G_Accuracy (%),G_Sensitivity (%),G_Specificity (%),G_Precision (%)\\n')\n","  accu_result = np.zeros((len(image_names), 4))\n","  for i, imagename in enumerate(image_names):\n","    total = results[i, 0]+results[i, 1]+results[i, 2]+results[i, 3]\n","    accu_result[i, 0]  = (results[i, 0]+results[i, 3])/total*100\n","    accu_result[i, 1]  = (results[i, 3]/(results[i, 2]+results[i, 3]))*100\n","    accu_result[i, 2]  = (results[i, 0]/(results[i, 0]+results[i, 1]))*100\n","    accu_result[i, 3]  = (results[i, 3]/(results[i, 1]+results[i, 3]))*100\n","    f.write('%s & %d & %d & %d & %d & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\\\hline\\n' % \n","        (imagename.split('-')[0], results[i, 0], results[i, 1], results[i, 2], results[i, 3], \n","            accu_result[i, 0], accu_result[i, 1], accu_result[i, 2], accu_result[i, 3]))\n","  f.write('Average & %d & %d & %d & %d & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\n' % \n","          (np.mean(results[:, 0]), np.mean(results[:, 1]), np.mean(results[:, 2]), np.mean(results[:, 3]), \n","              np.mean(accu_result[:, 0]), np.mean(accu_result[:, 1]), \n","              np.mean(accu_result[:, 2]), np.mean(accu_result[:, 3])))\n","  \n","  # White Matter\n","  f.write('Image Name,White_TN (px),White_FP (px),White_FN (px),White_TP (px),' +\n","          'W_Accuracy (%),W_Sensitivity (%),W_Specificity (%),W_Precision (%)\\n')\n","  accu_result = np.zeros((len(image_names), 4))\n","  for i, imagename in enumerate(image_names):\n","    total = results[i, 4]+results[i, 5]+results[i, 6]+results[i, 7] \n","    accu_result[i, 0]  = (results[i, 4]+results[i, 7])/total*100\n","    accu_result[i, 1]  = (results[i, 7]/(results[i, 6]+results[i, 7]))*100\n","    accu_result[i, 2]  = (results[i, 4]/(results[i, 4]+results[i, 5]))*100\n","    accu_result[i, 3] = (results[i, 7]/(results[i, 5]+results[i, 7]))*100\n","    f.write('%s & %d & %d & %d & %d & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\\\hline\\n' % \n","        (imagename.split('-')[0], results[i, 4], results[i, 5], results[i, 6], results[i, 7], \n","            accu_result[i, 0], accu_result[i, 1], accu_result[i, 2], accu_result[i, 3]))\n","  f.write('Average & %d & %d & %d & %d & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\n' % \n","          (np.mean(results[:, 4]), np.mean(results[:, 5]), np.mean(results[:, 6]), np.mean(results[:, 7]), \n","              np.mean(accu_result[:, 0]), np.mean(accu_result[:, 1]), \n","              np.mean(accu_result[:, 2]), np.mean(accu_result[:, 3])))\n","print('Done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image NA3777-02_AB, Test ((372, 432)), Ground Truth ((372, 432)):   0%|          | 0/18 [00:05<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4077-02_AB, Test ((372, 576)), Ground Truth ((372, 576)):   6%|▌         | 1/18 [00:13<02:32,  8.96s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4092-02_AB, Test ((360, 516)), Ground Truth ((360, 516)):  11%|█         | 2/18 [00:23<02:28,  9.25s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4107-02_AB, Test ((288, 540)), Ground Truth ((288, 540)):  17%|█▋        | 3/18 [00:30<02:15,  9.01s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4160-02_AB, Test ((336, 468)), Ground Truth ((336, 468)):  22%|██▏       | 4/18 [00:37<01:56,  8.36s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4195-02_AB, Test ((312, 444)), Ground Truth ((312, 444)):  28%|██▊       | 5/18 [00:44<01:43,  7.93s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4256-02_AB, Test ((372, 492)), Ground Truth ((372, 492)):  33%|███▎      | 6/18 [00:51<01:28,  7.36s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4299-02_AB, Test ((348, 456)), Ground Truth ((348, 456)):  39%|███▉      | 7/18 [00:58<01:23,  7.59s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4391-02_AB, Test ((372, 396)), Ground Truth ((372, 396)):  44%|████▍     | 8/18 [01:05<01:14,  7.42s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4450-02_AB, Test ((372, 456)), Ground Truth ((372, 456)):  50%|█████     | 9/18 [01:12<01:04,  7.14s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4463-02_AB, Test ((360, 432)), Ground Truth ((360, 432)):  56%|█████▌    | 10/18 [01:19<00:58,  7.29s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4471-02_AB, Test ((372, 564)), Ground Truth ((372, 564)):  61%|██████    | 11/18 [01:28<00:49,  7.13s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4553-02_AB, Test ((372, 540)), Ground Truth ((372, 540)):  67%|██████▋   | 12/18 [01:37<00:47,  7.92s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4626-02_AB, Test ((336, 384)), Ground Truth ((336, 384)):  72%|███████▏  | 13/18 [01:44<00:41,  8.30s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4672-02_AB, Test ((288, 396)), Ground Truth ((288, 396)):  78%|███████▊  | 14/18 [01:49<00:29,  7.42s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4675-02_AB, Test ((360, 432)), Ground Truth ((360, 432)):  83%|████████▎ | 15/18 [01:55<00:19,  6.60s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4691-02_AB, Test ((324, 432)), Ground Truth ((324, 432)):  89%|████████▉ | 16/18 [02:01<00:13,  6.65s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4695-02_AB, Test ((336, 444)), Ground Truth ((336, 444)):  94%|█████████▍| 17/18 [02:08<00:06,  6.47s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["\rImage NA4695-02_AB, Test ((336, 444)), Ground Truth ((336, 444)): 100%|██████████| 18/18 [02:11<00:00,  6.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"UDx7BOc7OANZ","colab_type":"text"},"source":["#### Calculate IoU and F1 score"]},{"cell_type":"code","metadata":{"id":"41jfDyD9wXpH","colab_type":"code","outputId":"b0608a4e-76c9-4ae9-8621-b377266bb0d1","executionInfo":{"status":"ok","timestamp":1576983406969,"user_tz":-480,"elapsed":207288,"user":{"displayName":"Kolin Guo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAH9P6dxFWxAyjWf-hm5lG4YWz-T3Rpw_iv40fA=s64","userId":"15703454620303738587"}},"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["#@title\n","SAVE_FILENAME = 'IoUResults.csv' # Under TEST_DIR\n","SAVE_FILENAME_LATEX = 'IoUResults.txt' # Under TEST_DIR\n","\n","# Stores results: back_TN, back_FP, back_FN, back_TP, grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP\n","conf_mat = np.zeros((len(image_names), 12), dtype='int')\n","# Stores accuracy results: back_IoU, back_F1, grey_IoU, grey_F1, white_IoU, white_F1\n","results = np.zeros((len(image_names), 6))\n","# Stores accuracy results: back_IoU_conf, back_F1_conf, grey_IoU_conf, grey_F1_conf, white_IoU_conf, white_F1_conf\n","results_conf = np.zeros((len(image_names), 6))\n","\n","t = tqdm(total=len(image_names))\n","for i, imagename in enumerate(image_names):\n","  # Filename for testing and ground truth images\n","  test_grey_img_name = imagename + \"-Grey.png\"\n","  test_white_img_name = imagename + \"-White.png\"\n","  test_back_img_name = imagename + \"-Background.png\"\n","  truth_grey_img_name = imagename + \"-Grey.png\"\n","  truth_white_img_name = imagename + \"-White.png\"\n","  truth_back_img_name = imagename + \"-Background.png\"\n","\n","  ##### Testing Background Mask #####\n","  # Load images\n","  test_img = np.array(Image.open(TEST_DIR + test_back_img_name))\n","  truth_img = Image.open(TRUTH_DIR + truth_back_img_name)\n","  (width, height) = (IMAGEDIMNORM[i, 0] // downscale, IMAGEDIMNORM[i, 1] // downscale)\n","  truth_img = truth_img.resize((width, height), Image.BILINEAR)\n","  truth_img = np.array(truth_img)\n","\n","  # Check dimensions and dtype\n","  if not (test_img.shape[0] == IMAGEDIMNORM[i, 1]//downscale and test_img.shape[1] == IMAGEDIMNORM[i, 0]//downscale):\n","    print('\\t' + imagename + ' background dimension WRONG!!!')\n","  assert(truth_img.dtype == np.bool)\n","\n","  # Update tqdm descriptions\n","  t.set_description_str(\"Image {}, Test ({}), Ground Truth ({})\".format(\n","      imagename, str(test_img.shape), str(truth_img.shape)) )\n","  t.refresh()\n","  t.write(\"\", end=' ')\n","\n","  # Clip test_img to 1\n","  test_img[test_img>=1] = 1\n","\n","  # Calculate true and false segmentations\n","  width = truth_img.shape[1]\n","  height = truth_img.shape[0]\n","  back_TP = np.multiply(test_img, truth_img).sum()\n","  back_FP = np.multiply(test_img, np.logical_not(truth_img)).sum()\n","  back_FN = np.multiply(np.logical_not(test_img), truth_img).sum()\n","  back_TN = np.multiply(np.logical_not(test_img), np.logical_not(truth_img)).sum()\n","\n","  # Check results\n","  back_total = width*height\n","  if not (back_total == back_TP+back_FP+back_FN+back_TN):\n","    print('\\t' + imagename + ' background results WRONG!!!')\n","\n","  # Calculate IoU and F1 score\n","  back_IoU = np.logical_and(test_img, truth_img).sum() / np.logical_or(test_img, truth_img).sum()\n","  back_F1 = np.logical_and(test_img, truth_img).sum() * 2 / (test_img.sum() + truth_img.sum())\n","\n","  # Calculate IoU and F1 score using TP FP FN\n","  back_IoU_conf = back_TP / (back_TP+back_FP+back_FN)\n","  back_F1_conf = 2*back_TP / (2*back_TP+back_FP+back_FN)\n","\n","  ##### Testing Grey Matter Mask #####\n","  # Load images\n","  test_img = np.array(Image.open(TEST_DIR + test_grey_img_name))\n","  truth_img = Image.open(TRUTH_DIR + truth_grey_img_name)\n","  (width, height) = (IMAGEDIMNORM[i, 0] // downscale, IMAGEDIMNORM[i, 1] // downscale)\n","  truth_img = truth_img.resize((width, height), Image.BILINEAR)\n","  truth_img = np.array(truth_img)\n","\n","  # Check dimensions and dtype\n","  if not (test_img.shape[0] == IMAGEDIMNORM[i, 1]//downscale and test_img.shape[1] == IMAGEDIMNORM[i, 0]//downscale):\n","    print('\\t' + imagename + ' grey dimension WRONG!!!')\n","  assert(truth_img.dtype == np.bool)\n","\n","  # Clip test_img to 1\n","  test_img[test_img>=1] = 1\n","\n","  # Calculate true and false segmentations\n","  width = truth_img.shape[1]\n","  height = truth_img.shape[0]\n","  grey_TP = np.multiply(test_img, truth_img).sum()\n","  grey_FP = np.multiply(test_img, np.logical_not(truth_img)).sum()\n","  grey_FN = np.multiply(np.logical_not(test_img), truth_img).sum()\n","  grey_TN = np.multiply(np.logical_not(test_img), np.logical_not(truth_img)).sum()\n","  \n","  # Check results\n","  grey_total = width*height\n","  if not (grey_total == grey_TP+grey_FP+grey_FN+grey_TN):\n","    print('\\t' + imagename + ' grey matter results WRONG!!!')\n","\n","  # Calculate IoU and F1 score\n","  grey_IoU = np.logical_and(test_img, truth_img).sum() / np.logical_or(test_img, truth_img).sum()\n","  grey_F1 = np.logical_and(test_img, truth_img).sum() * 2 / (test_img.sum() + truth_img.sum())\n","\n","  # Calculate IoU and F1 score using TP FP FN\n","  grey_IoU_conf = grey_TP / (grey_TP+grey_FP+grey_FN)\n","  grey_F1_conf = 2*grey_TP / (2*grey_TP+grey_FP+grey_FN)\n","\n","  ##### Testing White Matter Mask #####\n","  # Load images\n","  test_img = np.array(Image.open(TEST_DIR + test_white_img_name))\n","  truth_img = Image.open(TRUTH_DIR + truth_white_img_name)\n","  (width, height) = (IMAGEDIMNORM[i, 0] // downscale, IMAGEDIMNORM[i, 1] // downscale)\n","  truth_img = truth_img.resize((width, height), Image.BILINEAR)\n","  truth_img = np.array(truth_img)\n","\n","  # Check dimensions and dtype\n","  if not (test_img.shape[0] == IMAGEDIMNORM[i, 1]//downscale and test_img.shape[1] == IMAGEDIMNORM[i, 0]//downscale):\n","    print('\\t' + imagename + ' white dimension WRONG!!!')\n","  assert(truth_img.dtype == np.bool)\n","\n","  # Clip test_img to 1\n","  test_img[test_img>=1] = 1\n","\n","  # Calculate true and false segmentations\n","  width = truth_img.shape[1]\n","  height = truth_img.shape[0]\n","  white_TP = np.multiply(test_img, truth_img).sum()\n","  white_FP = np.multiply(test_img, np.logical_not(truth_img)).sum()\n","  white_FN = np.multiply(np.logical_not(test_img), truth_img).sum()\n","  white_TN = np.multiply(np.logical_not(test_img), np.logical_not(truth_img)).sum()\n","\n","  # Check results\n","  white_total = width*height\n","  if not (white_total == white_TN+white_FP+white_FN+white_TP):\n","    print('\\t' + imagename + ' white matter results WRONG!!!')\n","\n","  # Calculate IoU and F1 score\n","  white_IoU = np.logical_and(test_img, truth_img).sum() / np.logical_or(test_img, truth_img).sum()\n","  white_F1 = np.logical_and(test_img, truth_img).sum() * 2 / (test_img.sum() + truth_img.sum())\n","\n","  # Calculate IoU and F1 score using TP FP FN\n","  white_IoU_conf = white_TP / (white_TP+white_FP+white_FN)\n","  white_F1_conf = 2*white_TP / (2*white_TP+white_FP+white_FN)\n","\n","  # Save results: back_TN, back_FP, back_FN, back_TP, grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP\n","  conf_mat[i, :] = [back_TN, back_FP, back_FN, back_TP, grey_TN, grey_FP, grey_FN, grey_TP, white_TN, white_FP, white_FN, white_TP]\n","  # Stores accuracy results: back_IoU, back_F1, grey_IoU, grey_F1, white_IoU, white_F1\n","  results[i, :] = [back_IoU, back_F1, grey_IoU, grey_F1, white_IoU, white_F1]\n","  # Stores accuracy results: back_IoU_conf, back_F1_conf, grey_IoU_conf, grey_F1_conf, white_IoU_conf, white_F1_conf\n","  results_conf[i, :] = [back_IoU_conf, back_F1_conf, grey_IoU_conf, grey_F1_conf, white_IoU_conf, white_F1_conf]\n","\n","  t.update()\n","t.close()\n","\n","################################################################################\n","# Multiply results and results_conf by 100 (%)\n","results *= 100\n","results_conf *= 100\n","\n","# Average results: Avg_IoU (%),Avg_IoU_conf (%),Avg_F1 (%),Avg_F1_conf (%)\n","avg_result = np.zeros((len(image_names), 4))\n","avg_result[:, 0] = np.mean(results[:, 0:6:2], axis=1)\n","avg_result[:, 1] = np.mean(results_conf[:, 0:6:2], axis=1)\n","avg_result[:, 2] = np.mean(results[:, 1:6:2], axis=1)\n","avg_result[:, 3] = np.mean(results_conf[:, 1:6:2], axis=1)\n","\n","# Generate results file\n","with open(TEST_DIR + SAVE_FILENAME, \"w\") as f:\n","  f.write('Image Name,Back_TN (px),Back_FP (px),Back_FN (px),Back_TP (px),' +\n","          'Grey_TN (px),Grey_FP (px),Grey_FN (px),Grey_TP (px),' +\n","          'White_TN (px),White_FP (px),White_FN (px),White_TP (px),' + \n","          'Back_IoU (%),Back_IoU_conf (%),Back_F1 (%),Back_F1_conf (%),' +\n","          'Grey_IoU (%),Grey_IoU_conf (%),Grey_F1 (%),Grey_F1_conf (%),' +\n","          'White_IoU (%),White_IoU_conf (%),White_F1 (%),White_F1_conf (%),' +\n","          'Avg_IoU (%),Avg_IoU_conf (%),Avg_F1 (%),Avg_F1_conf (%)\\n') \n","\n","  for i, imagename in enumerate(image_names):\n","    f.write('%s,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f\\n' % \n","        (imagename, conf_mat[i, 0], conf_mat[i, 1], conf_mat[i, 2], conf_mat[i, 3], \n","            conf_mat[i, 4], conf_mat[i, 5], conf_mat[i, 6], conf_mat[i, 7], \n","            conf_mat[i, 8], conf_mat[i, 9], conf_mat[i, 10], conf_mat[i, 11], \n","            results[i, 0], results_conf[i, 0], results[i, 1], results_conf[i, 1], \n","            results[i, 2], results_conf[i, 2], results[i, 3], results_conf[i, 3], \n","            results[i, 4], results_conf[i, 4], results[i, 5], results_conf[i, 5],\n","            avg_result[i, 0], avg_result[i, 1], avg_result[i, 2], avg_result[i, 3])) \n","  f.write('-' * 230 + '\\n')\n","  f.write('Average,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f\\n' % \n","          (np.mean(conf_mat[:, 0]), np.mean(conf_mat[:, 1]), np.mean(conf_mat[:, 2]), np.mean(conf_mat[:, 3]), \n","              np.mean(conf_mat[:, 4]), np.mean(conf_mat[:, 5]), np.mean(conf_mat[:, 6]), np.mean(conf_mat[:, 7]), \n","              np.mean(conf_mat[:, 8]), np.mean(conf_mat[:, 9]), np.mean(conf_mat[:, 10]), np.mean(conf_mat[:, 11]), \n","              np.mean(results[:, 0]), np.mean(results_conf[:, 0]), np.mean(results[:, 1]), np.mean(results_conf[:, 1]), \n","              np.mean(results[:, 2]), np.mean(results_conf[:, 2]), np.mean(results[:, 3]), np.mean(results_conf[:, 3]), \n","              np.mean(results[:, 4]), np.mean(results_conf[:, 4]), np.mean(results[:, 5]), np.mean(results_conf[:, 5]),\n","              np.mean(avg_result[:, 0]), np.mean(avg_result[:, 1]), np.mean(avg_result[:, 2]), np.mean(avg_result[:, 3])))\n","\n","# Generate results file for LaTeX\n","with open(TEST_DIR + SAVE_FILENAME_LATEX, \"w\") as f:\n","  f.write('Image Name,Back_IoU (%),Back_F1 (%),Grey_IoU (%),Grey_F1 (%),White_IoU (%),White_F1 (%),Avg_IoU (%),Avg_F1 (%)\\n')\n","  for i, imagename in enumerate(image_names):\n","    f.write('%s & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\\\hline\\n' % \n","        (imagename.split('-')[0], results[i, 0], results[i, 1], results[i, 2], \n","            results[i, 3], results[i, 4], results[i, 5], \n","            avg_result[i, 0], avg_result[i, 2]))\n","  f.write('Average & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%% & %.2f\\\\%%\\\\\\\\\\n\\n' % \n","          (np.mean(results[:, 0]), np.mean(results[:, 1]), np.mean(results[:, 2]), \n","           np.mean(results[:, 3]), np.mean(results[:, 4]), np.mean(results[:, 5]),\n","              np.mean(avg_result[:, 0]), np.mean(avg_result[:, 2])))\n","print('Done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image NA3777-02_AB, Test ((372, 432)), Ground Truth ((372, 432)):   0%|          | 0/18 [00:10<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4077-02_AB, Test ((372, 576)), Ground Truth ((372, 576)):   6%|▌         | 1/18 [00:26<05:23, 19.02s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4092-02_AB, Test ((360, 516)), Ground Truth ((360, 516)):  11%|█         | 2/18 [00:43<05:04, 19.03s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4107-02_AB, Test ((288, 540)), Ground Truth ((288, 540)):  17%|█▋        | 3/18 [00:58<04:32, 18.17s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4160-02_AB, Test ((336, 468)), Ground Truth ((336, 468)):  22%|██▏       | 4/18 [01:11<03:50, 16.46s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4195-02_AB, Test ((312, 444)), Ground Truth ((312, 444)):  28%|██▊       | 5/18 [01:23<03:19, 15.35s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4256-02_AB, Test ((372, 492)), Ground Truth ((372, 492)):  33%|███▎      | 6/18 [01:36<02:50, 14.22s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4299-02_AB, Test ((348, 456)), Ground Truth ((348, 456)):  39%|███▉      | 7/18 [01:51<02:37, 14.28s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4391-02_AB, Test ((372, 396)), Ground Truth ((372, 396)):  44%|████▍     | 8/18 [02:03<02:21, 14.17s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4450-02_AB, Test ((372, 456)), Ground Truth ((372, 456)):  50%|█████     | 9/18 [02:15<02:01, 13.50s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4463-02_AB, Test ((360, 432)), Ground Truth ((360, 432)):  56%|█████▌    | 10/18 [02:29<01:49, 13.63s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"},{"output_type":"stream","text":["Image NA4471-02_AB, Test ((372, 564)), Ground Truth ((372, 564)):  61%|██████    | 11/18 [02:43<01:32, 13.27s/it]"],"name":"stderr"},{"output_type":"stream","text":[" "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"152iaJzViXG1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}