{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "train_path = np.load('/BrainSeg/data/patches_1024/train.npy')\n",
    "val_path = np.load('/BrainSeg/data/patches_1024/val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample function utilizing tf.keras.layers.Conv2D, size=4, strides=2, default set to be 2x resolution\n",
    "# based on reference http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/\n",
    "# upsample function, the size is determined by factor of images, strides is 2 * factor - factor % 2\n",
    "def upsample(filters, size=4, strides=2, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=strides,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_model(classes=3, drop_out_rate=0.2, bn=True):\n",
    "    # use dropout and bacth normalization to prevent overfitting and help to do quick convergence\n",
    "    # activation layer is added to incorporate non-linearity\n",
    "    \n",
    "    # input layer has variable length in width and height, tested on both 512, 1024\n",
    "    input_imgs = tf.keras.layers.Input(shape=(None, None, 3))\n",
    "    \n",
    "    # All the kernel size, filter, stride are based on comparson paper, maxpooling layer is based on original FCN paper\n",
    "    \n",
    "    # First conv layer + max pooling\n",
    "    x = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='same')(input_imgs)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    # Second conv layer + max pooling\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same')(pool1)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    # Third conv layer + max pooling\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(pool2)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    # Forth conv layer + max pooling\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(pool3)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)(x)  \n",
    "    \n",
    "    # Fifth conv layer + max pooling\n",
    "    x = tf.keras.layers.Conv2D(filters=1024, kernel_size=11, strides=1, padding=\"same\")(pool4)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    pool5 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    # build the fully connected layer using 1*1 convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(filters=512, kernel_size=1, strides=1, padding=\"same\")(pool5)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    conv6 = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=classes, kernel_size=1, strides=1, padding=\"same\")(conv6)\n",
    "    x = tf.keras.layers.Dropout(drop_out_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x, training=bn)\n",
    "    conv7 = tf.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "    # upsampling conv7 to 4x times and upsample pool4 to 2x times\n",
    "    up_conv7 = upsample(filters=classes, size=8, strides=4)(conv7)\n",
    "    up_pool4 = upsample(filters=64)(pool4)\n",
    "    \n",
    "    # Concatenate two resolutions\n",
    "    fuse_1 = tf.keras.layers.Concatenate()([up_conv7, up_pool4])\n",
    "    fuse_2 = tf.keras.layers.Concatenate()([fuse_1, pool3])\n",
    "    \n",
    "    prob = upsample(filters=classes, size=16, strides=8)(fuse_2)\n",
    "    model = tf.keras.Model(inputs=input_imgs, outputs=prob)\n",
    "    \n",
    "    print(model.summary())\n",
    "    print(\"FCN model building completes\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class structure, combine with numpy array color normalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from typing import Tuple\n",
    "from nptyping import NDArray\n",
    "from PIL import Image\n",
    "class BrainSegSequence(Sequence):\n",
    "    def __init__(self, image_paths: NDArray[str],\n",
    "            mask_paths: NDArray[str], batch_size: int):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths  = mask_paths\n",
    "        self.batch_size  = batch_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[NDArray[np.uint8], NDArray[np.uint8]]:\n",
    "        batch_x = self.image_paths[idx * self.batch_size : \n",
    "                (idx+1) * self.batch_size]\n",
    "        batch_y = self.mask_paths[idx * self.batch_size : \n",
    "                (idx+1) * self.batch_size]\n",
    "        return np.array([np.array(Image.open(p)) for p in batch_x])/255.0, \\\n",
    "                np.array([np.array(Image.open(p)) for p in batch_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training and val dataset with batchsize 16\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = BrainSegSequence(train_path[:,0], train_path[:,1], BATCH_SIZE)\n",
    "val_dataset = BrainSegSequence(val_path[:,0], val_path[:,1], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_filter(data_path, slide_index):\n",
    "    filter_ls = []\n",
    "    for ele in data_path:\n",
    "        if ele[0].split('/')[-2] == slide_index:\n",
    "            filter_ls.append(ele)\n",
    "        elif ele[0].split('/')[-2] == slide_index+'17-24':\n",
    "            filter_ls.append(ele)\n",
    "    dataset = BrainSegSequence(np.array(filter_ls)[:,0], np.array(filter_ls)[:,1], BATCH_SIZE)\n",
    "    return slide_index, filter_ls, dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_name_ls(address):\n",
    "    # Input the address of the text file, read in the train file names, and val file names\n",
    "    # return the length of train files, length of val files and train, val file lists\n",
    "    f = open(address, \"r\")\n",
    "    train_signal=False\n",
    "    val_signal = False\n",
    "    train_name_ls = [] \n",
    "    val_name_ls = []\n",
    "    for line in f:\n",
    "        if len(line.split('/')) > 1:\n",
    "            if line.split('/')[4][:2] == 'NA' and train_signal:\n",
    "                train_name_ls.append(line.split('/')[4][:12])\n",
    "            elif line.split('/')[4][:2] == 'NA' and val_signal:\n",
    "                val_name_ls.append(line.split('/')[4][:12])\n",
    "        else:\n",
    "            if line.split('/')[0] == '\\tTrain: \\n':\n",
    "                train_signal = True\n",
    "                val_signal = False\n",
    "            elif line.split('/')[0] == '\\tVal: \\n':\n",
    "                val_signal = True\n",
    "                train_signal = False\n",
    "    f.close()\n",
    "    return len(train_name_ls), len(val_name_ls), train_name_ls, val_name_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, train_file_ls, val_file_ls = slide_name_ls('/BrainSeg/data/patches_1024/dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NA4077-02_AB',\n",
       " 'NA4092-02_AB',\n",
       " 'NA4107-02_AB',\n",
       " 'NA4463-02_AB',\n",
       " 'NA4691-02_AB',\n",
       " 'NA4695-02_AB',\n",
       " 'NA4907-02_AB',\n",
       " 'NA4967-02_AB',\n",
       " 'NA4972-02_AB',\n",
       " 'NA4993-02_AB']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_file_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, slide_patches, _ = slide_filter(val_path, 'NA4092-02_AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 1 1216        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, None, 1 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 1 64          dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, None, None, 1 0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 3 12832       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, None, None, 3 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 3 128         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 3 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, None, None, 3 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 18496       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, None, None, 6 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 256         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, None, None, 6 0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 36928       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, None, 6 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 256         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, None, None, 6 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 1 7930880     max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, None, 1 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 1 4096        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 1 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, None, None, 1 0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 5 524800      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, None, 5 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 5 2048        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 5 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 3 1539        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, None, 3 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 3 12          dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, None, None, 3 588         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, None, None, 6 65792       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 6 0           sequential_6[0][0]               \n",
      "                                                                 sequential_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 1 0           concatenate_4[0][0]              \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, None, None, 3 100620      concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,700,551\n",
      "Trainable params: 8,696,981\n",
      "Non-trainable params: 3,570\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "FCN model building completes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5c03de11d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and compile model again, set the batchnormalization training to be false to use accumulated statistics\n",
    "model = fcn_model(classes=3, bn=True)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "# return the latest weights in the folder\n",
    "latest = tf.train.latest_checkpoint('/BrainSeg/baseline_code/weights/5_3_saved_weights/')\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/BrainSeg/data/patches_1024/images/NA4092-02_AB/NA4092-02_AB_(5120,26624,6144,27648).png\n",
      "[[1.1736017  1.1743646  1.1451836  ... 1.9570004  1.924956   1.9260137 ]\n",
      " [1.1426052  1.1491473  1.141493   ... 1.9587842  1.9629083  1.9610987 ]\n",
      " [1.1480409  1.1034244  1.1286006  ... 1.9370954  1.9466656  1.9415196 ]\n",
      " ...\n",
      " [0.8011799  0.8048097  0.8277071  ... 1.2787825  1.2990884  1.2757037 ]\n",
      " [0.80570656 0.8816708  0.779944   ... 1.2893971  1.2761605  1.3123007 ]\n",
      " [0.8060879  0.8610015  0.8768932  ... 1.2740865  1.2803231  1.2880399 ]]\n",
      "[[3.7366724 3.7254183 3.7000608 ... 3.4851897 3.4435124 3.4392262]\n",
      " [3.7114544 3.7152615 3.7279572 ... 3.4673617 3.470872  3.4746816]\n",
      " [3.7391784 3.6962245 3.7083287 ... 3.4754183 3.4628937 3.4595954]\n",
      " ...\n",
      " [3.893131  3.8913147 3.8896787 ... 3.3481724 3.3631155 3.339914 ]\n",
      " [3.895209  3.911492  3.8850205 ... 3.350753  3.35032   3.366082 ]\n",
      " [3.8805    3.908934  3.9129727 ... 3.3427687 3.3544912 3.3507946]]\n",
      "[[0.8764318  0.86422014 0.85100186 ... 0.47703266 0.44503433 0.44230196]\n",
      " [0.85701686 0.85665005 0.8764656  ... 0.46716985 0.46447495 0.4714751 ]\n",
      " [0.8864947  0.84240305 0.85413444 ... 0.46126217 0.45964932 0.4605068 ]\n",
      " ...\n",
      " [0.94273394 0.92618734 1.0322555  ... 0.94481933 0.948132   0.9371281 ]\n",
      " [0.93574494 1.0476978  0.93757087 ... 0.9339967  0.94219726 0.96182233]\n",
      " [0.9244579  1.0512525  1.0509877  ... 0.92491347 0.93926495 0.94258726]]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "/BrainSeg/data/patches_1024/images/NA4092-02_AB/NA4092-02_AB_(14336,37888,15360,38912).png\n",
      "[[1.0993983 1.0961773 1.0683596 ... 1.5989174 1.5700028 1.5640018]\n",
      " [1.0712943 1.0733519 1.0639237 ... 1.5908267 1.6073449 1.6011479]\n",
      " [1.0749258 1.0298694 1.0477873 ... 1.5661954 1.5800062 1.5719652]\n",
      " ...\n",
      " [1.3052661 1.301631  1.243792  ... 1.782304  1.819567  1.7879466]\n",
      " [1.3084958 1.2664123 1.2898812 ... 1.8001276 1.7856622 1.8232119]\n",
      " [1.3093063 1.2710329 1.2803825 ... 1.7860425 1.8121539 1.8094554]]\n",
      "[[3.8273327 3.8122303 3.7889974 ... 3.0793953 3.0428834 3.0320442]\n",
      " [3.8038757 3.8050234 3.8193343 ... 3.062539  3.070291  3.070723 ]\n",
      " [3.830364  3.7899153 3.7962828 ... 3.066052  3.0565324 3.048278 ]\n",
      " ...\n",
      " [3.382919  3.3816645 3.3130374 ... 3.419065  3.4511206 3.4207087]\n",
      " [3.3830223 3.3185804 3.3711584 ... 3.4266636 3.4287937 3.4424376]\n",
      " [3.3701477 3.3337758 3.3313973 ... 3.4155157 3.437763  3.435882 ]]\n",
      "[[0.5254771  0.51169634 0.49973702 ... 1.134047   1.0983332  1.0964506 ]\n",
      " [0.50910217 0.5105039  0.5271115  ... 1.1263801  1.1220374  1.1265427 ]\n",
      " [0.5368314  0.49609596 0.50409704 ... 1.1172003  1.1147532  1.1101817 ]\n",
      " ...\n",
      " [1.1784313  1.1585265  1.1218936  ... 0.5697182  0.5824773  0.5693951 ]\n",
      " [1.1715561  1.0952721  1.1720341  ... 0.5680436  0.5729186  0.58811504]\n",
      " [1.1598854  1.1434773  1.1251507  ... 0.55851126 0.57666236 0.5817744 ]]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "/BrainSeg/data/patches_1024/images/NA4092-02_AB/NA4092-02_AB_(31744,30720,32768,31744).png\n",
      "[[3.0651808 3.0573974 3.0524979 ... 3.2271926 3.1883304 3.1924393]\n",
      " [3.0333915 3.0557206 3.0670116 ... 3.2408886 3.2297907 3.2129452]\n",
      " [3.058472  3.0401087 3.0625885 ... 3.227322  3.2199273 3.2173252]\n",
      " ...\n",
      " [3.0623255 3.0831213 3.109118  ... 3.2192676 3.2336445 3.2049856]\n",
      " [3.07975   3.113885  3.0651324 ... 3.2334683 3.2160788 3.2288754]\n",
      " [3.0597305 3.114605  3.128541  ... 3.227687  3.2182887 3.2247593]]\n",
      "[[1.8223705 1.8129537 1.7974491 ... 2.0724425 2.0281427 2.0472138]\n",
      " [1.7935567 1.8118215 1.8191805 ... 2.0679665 2.0709467 2.0580716]\n",
      " [1.8296216 1.7887    1.8091682 ... 2.0533848 2.0503206 2.0541832]\n",
      " ...\n",
      " [1.7407905 1.7630683 1.7888252 ... 1.9470006 1.9532273 1.9422585]\n",
      " [1.7553182 1.7986994 1.7282223 ... 1.9514847 1.9571637 1.9555732]\n",
      " [1.723377  1.8002244 1.8099109 ... 1.9496905 1.9507896 1.9642754]]\n",
      "[[0.5901293  0.580812   0.567437   ... 0.6349728  0.6027917  0.6178044 ]\n",
      " [0.55963784 0.5784742  0.5884445  ... 0.629997   0.6280159  0.6320699 ]\n",
      " [0.59904623 0.56071043 0.57637197 ... 0.6201823  0.6195589  0.62421846]\n",
      " ...\n",
      " [0.538584   0.5446442  0.         ... 0.4727923  0.46931344 0.4638512 ]\n",
      " [0.548152   0.         0.53658515 ... 0.45970646 0.47161388 0.48117593]\n",
      " [0.5092208  0.         0.         ... 0.4622672  0.4680843  0.47688547]]\n",
      "(array([   0,    0,    0, ..., 1023, 1023, 1023]), array([   0,    1,    2, ..., 1021, 1022, 1023]))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "for patch in slide_patches[:3]:\n",
    "    print(patch[0])\n",
    "    loaded_patch = np.array([np.array(Image.open(patch[0]))])/255.0\n",
    "    #plt.imshow(loaded_patch[0], interpolation='nearest')\n",
    "    #plt.show()\n",
    "    result = model.predict(loaded_patch)\n",
    "    #plt.imshow(result[0], interpolation='nearest')\n",
    "    #plt.show()\n",
    "    print(result[0][:,:,0])\n",
    "    print(result[0][:,:,1])\n",
    "    print(result[0][:,:,2])\n",
    "    a = result[0][:,:,0]-result[0][:,:,1] > 0\n",
    "    b = result[0][:,:,0]-result[0][:,:,2] > 0\n",
    "    c = np.where(a & b == True)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_slides(file_ls, path):\n",
    "    # define and compile model again, set the batchnormalization training to be false to use accumulated statistics\n",
    "    model = fcn_model(classes=3, bn=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[ tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    # return the latest weights in the folder\n",
    "    latest = tf.train.latest_checkpoint('/BrainSeg/baseline_code/weights/5_3_saved_weights/')\n",
    "    # Load the previously saved weights\n",
    "    model.load_weights(latest)\n",
    "    for file in file_ls:\n",
    "        slide_index, data_size, cur_dataset = slide_filter(path, file)\n",
    "        # evaluate the model performance on this specific slide\n",
    "        loss, acc = model.evaluate(cur_dataset)\n",
    "        print(\"The {0} slide {1}: Accuracy: \".format('Validation', slide_index)+\"{:5.2f}%\".format(acc*100)+\", Losses: {:5.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 1216        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, None, None, 1 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 64          dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, None, None, 1 0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 3 12832       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, None, None, 3 0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 3 128         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 3 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, None, None, 3 0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 6 18496       max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, None, None, 6 0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 6 256         dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 6 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, None, None, 6 0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 6 36928       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, None, None, 6 0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 6 256         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 6 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, None, None, 6 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 7930880     max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, None, None, 1 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 4096        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, None, None, 1 0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 5 524800      max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, None, None, 5 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 5 2048        dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 3 1539        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, None, None, 3 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 3 12          dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 3 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_15 (Sequential)      (None, None, None, 3 588         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_16 (Sequential)      (None, None, None, 6 65792       max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, None, 6 0           sequential_15[0][0]              \n",
      "                                                                 sequential_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, None, None, 1 0           concatenate_10[0][0]             \n",
      "                                                                 max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_17 (Sequential)      (None, None, None, 3 100620      concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,700,551\n",
      "Trainable params: 8,696,981\n",
      "Non-trainable params: 3,570\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "FCN model building completes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5cdb9b6a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f5cdb9b6a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "207/207 [==============================] - 209s 1s/step - loss: 0.2654 - sparse_categorical_accuracy: 0.9369\n",
      "The Validation slide NA4077-02_AB: Accuracy: 93.69%, Losses: 0.2654\n",
      "183/183 [==============================] - 193s 1s/step - loss: 0.1578 - sparse_categorical_accuracy: 0.9508\n",
      "The Validation slide NA4092-02_AB: Accuracy: 95.08%, Losses: 0.1578\n",
      "151/151 [==============================] - 158s 1s/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9463\n",
      "The Validation slide NA4107-02_AB: Accuracy: 94.63%, Losses: 0.2053\n",
      " 45/150 [========>.....................] - ETA: 2:10 - loss: 0.3863 - sparse_categorical_accuracy: 0.8752"
     ]
    }
   ],
   "source": [
    "evaluate_slides(val_file_ls, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 1216        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, None, 1 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 1 64          dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, None, None, 1 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 3 12832       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, None, 3 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 3 128         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 3 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, None, None, 3 0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18496       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, None, None, 6 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 6 256         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, None, None, 6 0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, None, None, 6 0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 6 256         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 6 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, None, None, 6 0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 7930880     max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, None, None, 1 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 4096        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, None, None, 1 0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 5 524800      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, None, 5 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 5 2048        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 1539        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, None, None, 3 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 3 12          dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, None, None, 3 588         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, None, None, 6 65792       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 6 0           sequential_9[0][0]               \n",
      "                                                                 sequential_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, None, 1 0           concatenate_6[0][0]              \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, None, None, 3 100620      concatenate_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,700,551\n",
      "Trainable params: 8,696,981\n",
      "Non-trainable params: 3,570\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "FCN model building completes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f75c41e0840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f75c41e0840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "156/156 [==============================] - 159s 1s/step - loss: 0.2859 - sparse_categorical_accuracy: 0.9272\n",
      "The Validation slide NA3777-02_AB: Accuracy: 92.72%, Losses: 0.2859\n",
      "152/152 [==============================] - 155s 1s/step - loss: 0.1180 - sparse_categorical_accuracy: 0.9619\n",
      "The Validation slide NA4160-02_AB: Accuracy: 96.19%, Losses: 0.1180\n",
      "135/135 [==============================] - 141s 1s/step - loss: 0.1892 - sparse_categorical_accuracy: 0.9389\n",
      "The Validation slide NA4195-02_AB: Accuracy: 93.89%, Losses: 0.1892\n",
      "176/176 [==============================] - 190s 1s/step - loss: 0.3146 - sparse_categorical_accuracy: 0.9018\n",
      "The Validation slide NA4256-02_AB: Accuracy: 90.18%, Losses: 0.3146\n",
      "154/154 [==============================] - 162s 1s/step - loss: 0.2583 - sparse_categorical_accuracy: 0.9244\n",
      "The Validation slide NA4299-02_AB: Accuracy: 92.44%, Losses: 0.2583\n",
      "144/144 [==============================] - 153s 1s/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9426\n",
      "The Validation slide NA4391-02_AB: Accuracy: 94.26%, Losses: 0.1814\n",
      "168/168 [==============================] - 169s 1s/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9673\n",
      "The Validation slide NA4450-02_AB: Accuracy: 96.73%, Losses: 0.1140\n",
      "209/209 [==============================] - 207s 990ms/step - loss: 0.2210 - sparse_categorical_accuracy: 0.9359\n",
      "The Validation slide NA4471-02_AB: Accuracy: 93.59%, Losses: 0.2210\n",
      "197/197 [==============================] - 183s 926ms/step - loss: 0.2318 - sparse_categorical_accuracy: 0.9302\n",
      "The Validation slide NA4553-02_AB: Accuracy: 93.02%, Losses: 0.2318\n",
      "121/121 [==============================] - 128s 1s/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9246\n",
      "The Validation slide NA4626-02_AB: Accuracy: 92.46%, Losses: 0.2343\n",
      "111/111 [==============================] - 112s 1s/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9678\n",
      "The Validation slide NA4672-02_AB: Accuracy: 96.78%, Losses: 0.1018\n",
      "150/150 [==============================] - 154s 1s/step - loss: 0.1492 - sparse_categorical_accuracy: 0.9526\n",
      "The Validation slide NA4675-02_AB: Accuracy: 95.26%, Losses: 0.1492\n",
      "163/163 [==============================] - 165s 1s/step - loss: 0.2118 - sparse_categorical_accuracy: 0.9305\n",
      "The Validation slide NA4894-02_AB: Accuracy: 93.05%, Losses: 0.2118\n",
      "109/109 [==============================] - 104s 959ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9540\n",
      "The Validation slide NA4944-02_AB: Accuracy: 95.40%, Losses: 0.1316\n",
      "145/145 [==============================] - 138s 952ms/step - loss: 0.3519 - sparse_categorical_accuracy: 0.8879\n",
      "The Validation slide NA4971-02_AB: Accuracy: 88.79%, Losses: 0.3519\n",
      "86/86 [==============================] - 80s 936ms/step - loss: 0.2620 - sparse_categorical_accuracy: 0.9258\n",
      "The Validation slide NA4992-02_AB: Accuracy: 92.58%, Losses: 0.2620\n",
      "352/352 [==============================] - 381s 1s/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9113\n",
      "The Validation slide NA5010-02_AB: Accuracy: 91.13%, Losses: 0.2981\n",
      "143/143 [==============================] - 142s 990ms/step - loss: 0.1777 - sparse_categorical_accuracy: 0.9423\n",
      "The Validation slide NA5029-02_AB: Accuracy: 94.23%, Losses: 0.1777\n"
     ]
    }
   ],
   "source": [
    "evaluate_slides(train_file_ls, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
